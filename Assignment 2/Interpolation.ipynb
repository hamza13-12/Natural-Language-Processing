{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2928c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f0b816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenize the input text into lowercase words and punctuation.\"\"\"\n",
    "    return re.findall(r'\\b\\w+\\b|[^\\w\\s]', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dd197cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram_model(tokens, n):\n",
    "    \"\"\"Create and return N-gram models for 1 through n.\"\"\"\n",
    "    n_gram_counts = {}\n",
    "    context_counts = {}\n",
    "    \n",
    "    for order in range(1, n+1):\n",
    "        for i in range(len(tokens) - order + 1):\n",
    "            n_gram = tuple(tokens[i:i+order])\n",
    "            context = n_gram[:-1]\n",
    "            n_gram_counts[n_gram] = n_gram_counts.get(n_gram, 0) + 1\n",
    "            context_counts[context] = context_counts.get(context, 0) + 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    n_gram_probabilities = {}\n",
    "    for n_gram, count in n_gram_counts.items():\n",
    "        context = n_gram[:-1]\n",
    "        n_gram_probabilities[n_gram] = count / context_counts[context]\n",
    "    return n_gram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9af3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_models(models, weights):\n",
    "    \"\"\"Interpolate multiple N-gram models using given weights.\"\"\"\n",
    "    final_model = {}\n",
    "    for order, model in models.items():\n",
    "        for n_gram, prob in model.items():\n",
    "            if n_gram in final_model:\n",
    "                final_model[n_gram] += weights[order-1] * prob\n",
    "            else:\n",
    "                final_model[n_gram] = weights[order-1] * prob\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f69649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_words, num_words):\n",
    "    \"\"\"Generate text using an interpolated N-gram model.\"\"\"\n",
    "    \n",
    "    if isinstance(start_words, str):\n",
    "        start_words = tuple(start_words.split())\n",
    "    \n",
    "    text = list(start_words)\n",
    "    current_context = tuple(text[-2:])  # Start with the last two words for context\n",
    "    \n",
    "    for _ in range(num_words - len(start_words)):\n",
    "        possible_next_words = [n_gram[-1] for n_gram in model if n_gram[:-1] == current_context]\n",
    "        probabilities = [model[n_gram] for n_gram in model if n_gram[:-1] == current_context]\n",
    "        \n",
    "        if not probabilities:\n",
    "            break\n",
    "        \n",
    "        next_word = random.choices(possible_next_words, weights=probabilities)[0]\n",
    "        text.append(next_word)\n",
    "        current_context = (current_context[-1], next_word)  # Update context to last two words\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e0f84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corpus from a file\n",
    "with open(r\"C:\\Users\\Hamza\\Desktop\\NLP\\J. K. Rowling - Harry Potter 4 - The Goblet of Fire.txt\") as file:\n",
    "    corpus = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a53e5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(corpus)\n",
    "unigram_model = create_n_gram_model(tokens, 1)\n",
    "bigram_model = create_n_gram_model(tokens, 2)\n",
    "trigram_model = create_n_gram_model(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca88e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {1: unigram_model, 2: bigram_model, 3: trigram_model}\n",
    "weights = [0.1, 0.4, 0.5]  # Weights for unigram, bigram, trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48a57849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he had awoken with his wand - maker from whom harry would be quicker , i ' m not , wormtail ' s face , which none but the rippling weed . \" vot is wrong with me , if they had said , not even i can ' t he ? didn ' t have to really get to you all tonight , however , sirius would rather have done , straightened up , nodding toward the leprechauns , who opened his eyes still glinted malevolently through his hair . the dark and the students from beauxbatons and durmstrang\n"
     ]
    }
   ],
   "source": [
    "interpolated_model = interpolate_models(models, weights)\n",
    "generated_text = generate_text(interpolated_model, \"he had awoken\", 100)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc808a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
